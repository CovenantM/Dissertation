{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0072e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing important librairies\n",
    "import pyreadstat\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c05d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of the datasets\n",
    "dfs_names = [\"TGIR61FL\", \"SLIR7AFL\",\"SNIR8BFL\",\"NGIR7BFL\",\"MLIR7AFL\", \"GMIR81FL\",\"CIIR62FL\",\"NIIR61FL\",\"MRIR71FL\",\"GNIR71FL\",\"GHIR72FL\", \"BJIR71FL\",\"LBIR7AFL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fad025e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all the 13 dataset in SPSS format using the pyreadstat package\n",
    "list_of_df = []\n",
    "for countries in dfs_names:\n",
    "    data, _ = pyreadstat.read_sav(\"Data2/\"+countries+\".SAV\", encoding=\"latin1\")\n",
    "    list_of_df.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bb5cc00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASEID</th>\n",
       "      <th>V000</th>\n",
       "      <th>V001</th>\n",
       "      <th>V002</th>\n",
       "      <th>V003</th>\n",
       "      <th>V004</th>\n",
       "      <th>V005</th>\n",
       "      <th>V006</th>\n",
       "      <th>V007</th>\n",
       "      <th>V008</th>\n",
       "      <th>...</th>\n",
       "      <th>S538E$3</th>\n",
       "      <th>S538E$4</th>\n",
       "      <th>S538E$5</th>\n",
       "      <th>S538E$6</th>\n",
       "      <th>S538G$1</th>\n",
       "      <th>S538G$2</th>\n",
       "      <th>S538G$3</th>\n",
       "      <th>S538G$4</th>\n",
       "      <th>S538G$5</th>\n",
       "      <th>S538G$6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 1  2</td>\n",
       "      <td>GH6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>858896.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1379.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 3  2</td>\n",
       "      <td>GH6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>858896.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1379.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 5  2</td>\n",
       "      <td>GH6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>858896.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1378.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 5  3</td>\n",
       "      <td>GH6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>858896.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1378.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 6  2</td>\n",
       "      <td>GH6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>858896.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1378.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4079 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CASEID V000  V001  V002  V003  V004      V005  V006    V007  \\\n",
       "0           1 1  2  GH6   1.0   1.0   2.0   1.0  858896.0  11.0  2014.0   \n",
       "1           1 3  2  GH6   1.0   3.0   2.0   1.0  858896.0  11.0  2014.0   \n",
       "2           1 5  2  GH6   1.0   5.0   2.0   1.0  858896.0  10.0  2014.0   \n",
       "3           1 5  3  GH6   1.0   5.0   3.0   1.0  858896.0  10.0  2014.0   \n",
       "4           1 6  2  GH6   1.0   6.0   2.0   1.0  858896.0  10.0  2014.0   \n",
       "\n",
       "     V008  ...  S538E$3  S538E$4  S538E$5  S538E$6  S538G$1  S538G$2  S538G$3  \\\n",
       "0  1379.0  ...      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "1  1379.0  ...      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "2  1378.0  ...      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "3  1378.0  ...      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "4  1378.0  ...      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "   S538G$4  S538G$5  S538G$6  \n",
       "0      NaN      NaN      NaN  \n",
       "1      NaN      NaN      NaN  \n",
       "2      NaN      NaN      NaN  \n",
       "3      NaN      NaN      NaN  \n",
       "4      NaN      NaN      NaN  \n",
       "\n",
       "[5 rows x 4079 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the head of the first table (just for exploration)lem()\n",
    "list_of_df[10].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6397d955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the columns that we need in all cross data sets and store the datasets in a new list\n",
    "filtered_data = []\n",
    "for data_set in list_of_df:\n",
    "    filtered_data.append(data_set[[\"CASEID\", \"V000\",\"V005\", \"V007\",\"V010\",\"V013\", \"V153\", \"V102\", \"V119\", \"V190\", \"V120\", \"V121\", \"V122\", \"V123\", \"V124\", \"V125\",\n",
    "    \"V149\", \"V155\", \"V106\", \"V107\", \"V137\", \"V138\", \"V704\", \"V745A\",\"V745B\", \"V811\", \"V743A\", \"V717\",\"V739\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d32f53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the datasets togheter\n",
    "concatenated_d = pd.concat(filtered_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "06786d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179105, 29)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "314f0637",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data2 = []\n",
    "for i, data_set in enumerate(list_of_df):\n",
    "    if i in [2, 9, 10]:\n",
    "        zero_filled_df = pd.DataFrame(0, columns=mm_list, index=data_set.index)\n",
    "        filtered_data2.append(zero_filled_df)\n",
    "    else:\n",
    "        filtered_data2.append(data_set[mm_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "07474903",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_d2 = pd.concat(filtered_data2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "89cca770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179105, 20)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_d2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = concatenated_d2\n",
    "columns = concatenated_d2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "50cb123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We an have answer in the form about materal mortality, these questions are repeated 20 times for every respondant.\n",
    "# In the below we combine the answers and create 8 columns, each being an answer option for the questions.\n",
    "\n",
    "values_to_count = [1, 2, 3, 4, 5, 6, 98, 99]\n",
    "def count_occurrences(row, value):\n",
    "    return row.tolist().count(value)\n",
    "\n",
    "for value in values_to_count:\n",
    "    df[f'occurrences_{value}'] = df.apply(lambda row: count_occurrences(row, value), axis=1)\n",
    "\n",
    "columns_to_drop = columns\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "09139ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_d['index_col'] = range(len(concatenated_d))\n",
    "df['index_col'] = range(len(df))\n",
    "\n",
    "# Merge the DataFrames based on the index column\n",
    "merged_df = pd.merge(concatenated_d, df, on='index_col', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "bcf8fd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df\n",
    "merged_df = merged_df.drop(columns=[\"index_col\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "460d2c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New column names\n",
    "column_names = [\n",
    "    'CASE_ID', 'COUNTRY', 'SAMPLE_WEIGHT', 'YEAR_INTERVIEW', 'YEAR_DOB', 'AGE_5_YEAR_GROUP',\n",
    "    'TELEPHONE', 'TYPE_RESIDENCE', 'ELECTRICITY', 'WEALTH_INDEX', 'RADIO', 'TELEVISION',\n",
    "    'REFRIGERATOR', 'BICYCLE', 'MOTOCYCLE', 'CAR', 'EDUCATIONAL_ATTAINMENT', 'LITERACY',\n",
    "    'HIGHEST_EDUCATION_LEVEL', 'HIGHEST_YEAR_EDUCATION', 'NUMBER_OF_CHILDREN_UNDER_5',\n",
    "    'NUMBER_ELIGIBLE_WOMEN', 'HUSBAND_OCCUPATION', 'OWNS_HOUSE', 'OWNS_LAND',\n",
    "    'CHIL_UNDER_10_WIFE_BEATING', 'OWNS_HEALTH_CARE', 'REPONDANTS_OCCUPATION',\"EXPENSE_DECIDER\",\n",
    "    'DEATH_NOT_RELATED', 'DIED_WHILE_PREGNANT', 'DIED_DURING_DELIVERY', 'DIED_SINCE_DELIVERY',\n",
    "    'DIED_6_WEEKS_AFTER_DELIVERY', 'DIED_2_MONTHS_AFTER_DELIVERY', 'DONT_KNOW', 'MISSING'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a3ee82e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "718ce340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame to Excel\n",
    "file_name = 'full_dataset.xlsx'\n",
    "merged_df.to_excel(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b93131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To prepare the data for dashboarding, we firt load the SPSS country by country using the pyreadstat python package. We then proceeded to deciding the \n",
    "columns that we want to keep for our study. We chose columms that provided information about maternal mortality and income inequaty. Consequently we combined all the datasets by \n",
    "overlapping them, making them 1 single dataset. In some instances, certain questions are asked 20 times to the same respondant, we used our own python programs to combine the 20 answers into fewer columns.\n",
    "Finally we downloaded the dataset as an excel database and imported into tableau.\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
